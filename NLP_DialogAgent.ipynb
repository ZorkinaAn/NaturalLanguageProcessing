{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание:\n",
    "\n",
    "1) выбрать архитектуру диалогового агента (генеративная/ранжирующая)\n",
    "2) обучить на русскоязычном наборе диалогов (например https://www.kaggle.com/datasets/valentinbiryukov/toloka-persona-chat-rus)\n",
    "3) опционально добавить возможность персонификации (при желании)\n",
    "\n",
    "В результате должен получиться инференс диалогового агента, где можно вести диалог (способ ввода на ваше усмотрение, можно просто на инпутах)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-11T22:16:51.115099Z",
     "iopub.status.busy": "2023-12-11T22:16:51.114747Z",
     "iopub.status.idle": "2023-12-11T22:16:51.120766Z",
     "shell.execute_reply": "2023-12-11T22:16:51.119769Z",
     "shell.execute_reply.started": "2023-12-11T22:16:51.115073Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.functional.text import bleu_score\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import lightning.pytorch as pl\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = 'http://proxy.stc:3128'\n",
    "os.environ['https_proxy'] = 'http://proxy.stc:3128'\n",
    "os.environ['ftp_proxy'] = 'http://proxy.stc:3128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T22:16:56.933302Z",
     "iopub.status.busy": "2023-12-11T22:16:56.932648Z",
     "iopub.status.idle": "2023-12-11T22:16:57.932806Z",
     "shell.execute_reply": "2023-12-11T22:16:57.931677Z",
     "shell.execute_reply.started": "2023-12-11T22:16:56.933271Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 12 06:59:52 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 525.147.05   Driver Version: 525.147.05   CUDA Version: 12.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| 46%   67C    P2    65W / 250W |   1084MiB / 11264MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A       852      G   /usr/lib/xorg/Xorg                  9MiB |\r\n",
      "|    0   N/A  N/A      1029      G   /usr/bin/gnome-shell                3MiB |\r\n",
      "|    0   N/A  N/A     83017      C   ...ain/srlab_venv/bin/python      894MiB |\r\n",
      "|    0   N/A  N/A     93591      C   /usr/bin/python3                  172MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T22:20:30.100152Z",
     "iopub.status.busy": "2023-12-11T22:20:30.099776Z",
     "iopub.status.idle": "2023-12-11T22:20:30.716218Z",
     "shell.execute_reply": "2023-12-11T22:20:30.715243Z",
     "shell.execute_reply.started": "2023-12-11T22:20:30.100125Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>persona_1_profile</th>\n",
       "      <th>persona_2_profile</th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;span class=participant_1&gt;У меня любимая работ...</td>\n",
       "      <td>&lt;span class=participant_2&gt;Ищу принца.&lt;br /&gt;Вед...</td>\n",
       "      <td>&lt;span class=participant_2&gt;Пользователь 2: Прив...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;span class=participant_1&gt;Я работаю учителем&lt;b...</td>\n",
       "      <td>&lt;span class=participant_2&gt;Я бизнесмен&lt;br /&gt;У м...</td>\n",
       "      <td>&lt;span class=participant_1&gt;Пользователь 1: Прив...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;span class=participant_1&gt;Я купила дом&lt;br /&gt;Я ...</td>\n",
       "      <td>&lt;span class=participant_2&gt;Я пою в караоке&lt;br /...</td>\n",
       "      <td>&lt;span class=participant_1&gt;Пользователь 1: Прив...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;span class=participant_1&gt;я врач и женат&lt;br /&gt;...</td>\n",
       "      <td>&lt;span class=participant_2&gt;Я мальчик&lt;br /&gt;Я учу...</td>\n",
       "      <td>&lt;span class=participant_2&gt;Пользователь 2: Здра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;span class=participant_1&gt;Я школьница.&lt;br /&gt;Я ...</td>\n",
       "      <td>&lt;span class=participant_2&gt;Я простоват.&lt;br /&gt;Лю...</td>\n",
       "      <td>&lt;span class=participant_1&gt;Пользователь 1: Прив...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   persona_1_profile  \\\n",
       "0  <span class=participant_1>У меня любимая работ...   \n",
       "1  <span class=participant_1>Я работаю учителем<b...   \n",
       "2  <span class=participant_1>Я купила дом<br />Я ...   \n",
       "3  <span class=participant_1>я врач и женат<br />...   \n",
       "4  <span class=participant_1>Я школьница.<br />Я ...   \n",
       "\n",
       "                                   persona_2_profile  \\\n",
       "0  <span class=participant_2>Ищу принца.<br />Вед...   \n",
       "1  <span class=participant_2>Я бизнесмен<br />У м...   \n",
       "2  <span class=participant_2>Я пою в караоке<br /...   \n",
       "3  <span class=participant_2>Я мальчик<br />Я учу...   \n",
       "4  <span class=participant_2>Я простоват.<br />Лю...   \n",
       "\n",
       "                                            dialogue  \n",
       "0  <span class=participant_2>Пользователь 2: Прив...  \n",
       "1  <span class=participant_1>Пользователь 1: Прив...  \n",
       "2  <span class=participant_1>Пользователь 1: Прив...  \n",
       "3  <span class=participant_2>Пользователь 2: Здра...  \n",
       "4  <span class=participant_1>Пользователь 1: Прив...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('dialogues.tsv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T22:21:17.056812Z",
     "iopub.status.busy": "2023-12-11T22:21:17.056110Z",
     "iopub.status.idle": "2023-12-11T22:21:17.062753Z",
     "shell.execute_reply": "2023-12-11T22:21:17.061926Z",
     "shell.execute_reply.started": "2023-12-11T22:21:17.056777Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<span class=participant_2>Пользователь 2: Привет) расскажи о себе</span><br /><span class=participant_1>Пользователь 1: Привет) под вкусный кофеек настроение поболтать появилось<br />)</span><br /><span class=participant_2>Пользователь 2: Что читаешь? Мне нравится классика</span><br /><span class=participant_2>Пользователь 2: Я тоже люблю пообщаться</span><br /><span class=participant_1>Пользователь 1: Люблю животных, просто обожаю, как и свою работу)</span><br /><span class=participant_1>Пользователь 1: Я фантастику люблю</span><br /><span class=participant_2>Пользователь 2: А я выращиваю фиалки</span><br /><span class=participant_2>Пользователь 2: И веду здоровый и активный образ жизни!</span><br /><span class=participant_1>Пользователь 1: Ух ты, интересно.</span><br /><span class=participant_2>Пользователь 2: Ты случайно не принц на белом коне? Я его очень жду<br />..</span><br /><span class=participant_1>Пользователь 1: А у меня из хобби каждую неделю тусить с моим лучшим<br />другом)</span><br />'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dialogue'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(dialog):\n",
    "    res = []\n",
    "    #prev = dialog.split('</span>')[0].split(':')[0][-1]\n",
    "    prev = ''\n",
    "    #print(prev)\n",
    "    for sentence in dialog.split('</span>'):\n",
    "        s = sentence.split(':')\n",
    "        curr = s[0][-1]\n",
    "        if curr != prev:\n",
    "            if curr == '1':\n",
    "                msg = \"<Person1>\" + s[1].replace('<br />', '') + ' '\n",
    "                res.append(msg)\n",
    "            if curr == '2':\n",
    "                msg = \"<Person2>\" + s[1].replace('<br />', '') + ' '\n",
    "                res.append(msg)\n",
    "        else:\n",
    "            msg = s[1].replace('<br />', '') + ' '\n",
    "            res[-1]+=msg\n",
    "        prev = curr    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<Person1> Привет  Как дела ? ',\n",
       " '<Person2> Добрый день!  Хорошо,  чем увлекаетесь? ',\n",
       " '<Person1> Я бегаю по утрам а ты?  Есть любимые вещи или еда ?  Занят ? ',\n",
       " '<Person2> Я люблю петь в караоке) ',\n",
       " '<Person1> Круто ) ',\n",
       " '<Person2> Люблю готовить пасту,  у меня классно получается!  Любишь готовить? ',\n",
       " '<Person1> Это хорошо  Я не эксперт  Я люблю есть арбуз ']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_data(df[\"dialogue\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T00:49:40.391595Z",
     "iopub.status.busy": "2023-12-12T00:49:40.390691Z",
     "iopub.status.idle": "2023-12-12T00:49:40.855162Z",
     "shell.execute_reply": "2023-12-12T00:49:40.854185Z",
     "shell.execute_reply.started": "2023-12-12T00:49:40.391551Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"processd_dialog\"] = df[\"dialogue\"].map(process_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context(my_list):\n",
    "    return \" \".join(element for element in my_list[:-1])\n",
    "\n",
    "def answer(my_list):\n",
    "    return my_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"context\"] = df[\"processd_dialog\"].map(context)\n",
    "df[\"answer\"] = df[\"processd_dialog\"].map(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<Person2> Привет) расскажи о себе  <Person1> Привет) под вкусный кофеек настроение поболтать появилось)  <Person2> Что читаешь? Мне нравится классика  Я тоже люблю пообщаться  <Person1> Люблю животных, просто обожаю, как и свою работу)  Я фантастику люблю  <Person2> А я выращиваю фиалки  И веду здоровый и активный образ жизни!  <Person1> Ух ты, интересно.  <Person2> Ты случайно не принц на белом коне? Я его очень жду.. '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"context\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>persona_1_profile</th>\n",
       "      <th>persona_2_profile</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>processd_dialog</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;span class=participant_1&gt;У меня любимая работ...</td>\n",
       "      <td>&lt;span class=participant_2&gt;Ищу принца.&lt;br /&gt;Вед...</td>\n",
       "      <td>&lt;span class=participant_2&gt;Пользователь 2: Прив...</td>\n",
       "      <td>[&lt;Person2&gt; Привет) расскажи о себе , &lt;Person1&gt;...</td>\n",
       "      <td>&lt;Person2&gt; Привет) расскажи о себе  &lt;Person1&gt; П...</td>\n",
       "      <td>&lt;Person1&gt; А у меня из хобби каждую неделю туси...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;span class=participant_1&gt;Я работаю учителем&lt;b...</td>\n",
       "      <td>&lt;span class=participant_2&gt;Я бизнесмен&lt;br /&gt;У м...</td>\n",
       "      <td>&lt;span class=participant_1&gt;Пользователь 1: Прив...</td>\n",
       "      <td>[&lt;Person1&gt; Привет! , &lt;Person2&gt; Привет,Как жизн...</td>\n",
       "      <td>&lt;Person1&gt; Привет!  &lt;Person2&gt; Привет,Как жизнь?...</td>\n",
       "      <td>&lt;Person2&gt; Да я надеюсь на это,люблю ее</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;span class=participant_1&gt;Я купила дом&lt;br /&gt;Я ...</td>\n",
       "      <td>&lt;span class=participant_2&gt;Я пою в караоке&lt;br /...</td>\n",
       "      <td>&lt;span class=participant_1&gt;Пользователь 1: Прив...</td>\n",
       "      <td>[&lt;Person1&gt; Привет  Как дела ? , &lt;Person2&gt; Добр...</td>\n",
       "      <td>&lt;Person1&gt; Привет  Как дела ?  &lt;Person2&gt; Добрый...</td>\n",
       "      <td>&lt;Person1&gt; Это хорошо  Я не эксперт  Я люблю ес...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;span class=participant_1&gt;я врач и женат&lt;br /&gt;...</td>\n",
       "      <td>&lt;span class=participant_2&gt;Я мальчик&lt;br /&gt;Я учу...</td>\n",
       "      <td>&lt;span class=participant_2&gt;Пользователь 2: Здра...</td>\n",
       "      <td>[&lt;Person2&gt; Здравствуйте  Я Леша , &lt;Person1&gt; Зд...</td>\n",
       "      <td>&lt;Person2&gt; Здравствуйте  Я Леша  &lt;Person1&gt; Здра...</td>\n",
       "      <td>&lt;Person2&gt; А... а я на машину...  Ого</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;span class=participant_1&gt;Я школьница.&lt;br /&gt;Я ...</td>\n",
       "      <td>&lt;span class=participant_2&gt;Я простоват.&lt;br /&gt;Лю...</td>\n",
       "      <td>&lt;span class=participant_1&gt;Пользователь 1: Прив...</td>\n",
       "      <td>[&lt;Person1&gt; Привет! , &lt;Person2&gt; Привет!  Как тв...</td>\n",
       "      <td>&lt;Person1&gt; Привет!  &lt;Person2&gt; Привет!  Как твои...</td>\n",
       "      <td>&lt;Person2&gt; Поздно уже может до завтра? СПОКОЙНО...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   persona_1_profile  \\\n",
       "0  <span class=participant_1>У меня любимая работ...   \n",
       "1  <span class=participant_1>Я работаю учителем<b...   \n",
       "2  <span class=participant_1>Я купила дом<br />Я ...   \n",
       "3  <span class=participant_1>я врач и женат<br />...   \n",
       "4  <span class=participant_1>Я школьница.<br />Я ...   \n",
       "\n",
       "                                   persona_2_profile  \\\n",
       "0  <span class=participant_2>Ищу принца.<br />Вед...   \n",
       "1  <span class=participant_2>Я бизнесмен<br />У м...   \n",
       "2  <span class=participant_2>Я пою в караоке<br /...   \n",
       "3  <span class=participant_2>Я мальчик<br />Я учу...   \n",
       "4  <span class=participant_2>Я простоват.<br />Лю...   \n",
       "\n",
       "                                            dialogue  \\\n",
       "0  <span class=participant_2>Пользователь 2: Прив...   \n",
       "1  <span class=participant_1>Пользователь 1: Прив...   \n",
       "2  <span class=participant_1>Пользователь 1: Прив...   \n",
       "3  <span class=participant_2>Пользователь 2: Здра...   \n",
       "4  <span class=participant_1>Пользователь 1: Прив...   \n",
       "\n",
       "                                     processd_dialog  \\\n",
       "0  [<Person2> Привет) расскажи о себе , <Person1>...   \n",
       "1  [<Person1> Привет! , <Person2> Привет,Как жизн...   \n",
       "2  [<Person1> Привет  Как дела ? , <Person2> Добр...   \n",
       "3  [<Person2> Здравствуйте  Я Леша , <Person1> Зд...   \n",
       "4  [<Person1> Привет! , <Person2> Привет!  Как тв...   \n",
       "\n",
       "                                             context  \\\n",
       "0  <Person2> Привет) расскажи о себе  <Person1> П...   \n",
       "1  <Person1> Привет!  <Person2> Привет,Как жизнь?...   \n",
       "2  <Person1> Привет  Как дела ?  <Person2> Добрый...   \n",
       "3  <Person2> Здравствуйте  Я Леша  <Person1> Здра...   \n",
       "4  <Person1> Привет!  <Person2> Привет!  Как твои...   \n",
       "\n",
       "                                              answer  \n",
       "0  <Person1> А у меня из хобби каждую неделю туси...  \n",
       "1            <Person2> Да я надеюсь на это,люблю ее   \n",
       "2  <Person1> Это хорошо  Я не эксперт  Я люблю ес...  \n",
       "3              <Person2> А... а я на машину...  Ого   \n",
       "4  <Person2> Поздно уже может до завтра? СПОКОЙНО...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('dialogue_test.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('dialogue_train.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dialogue_dataset.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f572a3d486f4cf190c55bfe8f98dd71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9d4aefc56134f0db921b70dd33dab62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74c046d5cea4340904c47633f8d8850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83bcca0b05074eb0a48c434517519a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_files = {\"train\": \"dialogue_train.csv\", \"test\": \"dialogue_test.csv\"}\n",
    "dataset = load_dataset(\"csv\", data_files=data_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T23:37:33.775414Z",
     "iopub.status.busy": "2023-12-11T23:37:33.774941Z",
     "iopub.status.idle": "2023-12-11T23:37:33.780396Z",
     "shell.execute_reply": "2023-12-11T23:37:33.779189Z",
     "shell.execute_reply.started": "2023-12-11T23:37:33.775353Z"
    }
   },
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T22:13:01.311467Z",
     "iopub.status.busy": "2023-12-11T22:13:01.311066Z",
     "iopub.status.idle": "2023-12-11T22:13:01.327006Z",
     "shell.execute_reply": "2023-12-11T22:13:01.325815Z",
     "shell.execute_reply.started": "2023-12-11T22:13:01.311438Z"
    }
   },
   "outputs": [],
   "source": [
    "class GenDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, model_name_or_path, dataset):\n",
    "        super().__init__()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, truncation_side=\"left\", padding_side='left')\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        #self.model = AutoModelForCausalLM.from_pretrained(model_name_or_path, pad_token_id=self.tokenizer.eos_token_id)\n",
    "        self.ds = dataset\n",
    "        #self.tokenizer.add_tokens([\"<Person1>\", \"<Person2>\"])\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        \n",
    "        for split in self.ds:\n",
    "            \n",
    "            #self.ds[split] = self.ds[split].select(list(range(5000)))\n",
    "            if split == \"test\":\n",
    "                self.ds[split] = self.ds[split].map(self.test_tokenize)\n",
    "            else:\n",
    "                self.ds[split] = self.ds[split].map(self.tokenize)\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        train_split = self.ds[\"train\"]\n",
    "        return DataLoader(train_split, batch_size=4, collate_fn=self.collate)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        val_split = self.ds[\"test\"]\n",
    "        return DataLoader(val_split, batch_size=4, collate_fn=self.collate)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        test_split = self.ds[\"test\"]\n",
    "        return DataLoader(test_split, batch_size=4, collate_fn=self.collate_test)\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        pred_split = self.ds[\"test\"]\n",
    "        return DataLoader(pred_split, batch_size=4, collate_fn=self.collate_test)\n",
    "    \n",
    "    def tokenize(self, row):\n",
    "        row = self.tokenizer(f'{row[\"context\"]} {row[\"answer\"]}', max_length=128, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "        return row\n",
    "    \n",
    "    def test_tokenize(self, row):\n",
    "        row = self.tokenizer(f'{row[\"context\"]} {row[\"answer\"]}[:9]', max_length=128, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "        return row\n",
    "    \n",
    "    def collate(self, samples):\n",
    "        input_ids = torch.stack([torch.tensor(s[\"input_ids\"]).squeeze() for s in samples])\n",
    "        attention_mask = torch.stack([torch.tensor(s[\"attention_mask\"]).squeeze() for s in samples])\n",
    "        \n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T22:12:44.398469Z",
     "iopub.status.busy": "2023-12-11T22:12:44.397310Z",
     "iopub.status.idle": "2023-12-11T22:12:44.412136Z",
     "shell.execute_reply": "2023-12-11T22:12:44.411156Z",
     "shell.execute_reply.started": "2023-12-11T22:12:44.398436Z"
    }
   },
   "outputs": [],
   "source": [
    "class GenModel(pl.LightningModule):\n",
    "    def __init__(self, model_name_or_path):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, truncation_side=\"left\", padding_side='left')\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_name_or_path, pad_token_id=self.tokenizer.eos_token_id)\n",
    "        #self.tokenizer.add_tokens([\"<Person1>\", \"<Person2>\"])\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        loss = self.model(input_ids=batch[\"input_ids\"].to(device=\"cuda\"), attention_mask=batch[\"attention_mask\"].to(device=\"cuda\"), labels=batch[\"input_ids\"].to(device=\"cuda\")).loss\n",
    "        self.log(\"train_loss\", loss.item(), prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        val_loss = self.model(input_ids=batch[\"input_ids\"].to(device=\"cuda\"), attention_mask=batch[\"attention_mask\"].to(device=\"cuda\"), labels=batch[\"input_ids\"].to(device=\"cuda\")).loss\n",
    "        self.log(\"val_loss\", val_loss.item(), prog_bar=True)\n",
    "        return val_loss\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        outputs = self.model.generate(batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"], max_new_tokens=200)\n",
    "        \n",
    "        preds = []\n",
    "        for i in range(len(outputs)):\n",
    "            pred = self.tokenizer.decode(outputs[i], skip_special_tokens=True)\n",
    "            preds.append(pred)\n",
    "        \n",
    "        return preds\n",
    "    \n",
    "    def infer(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors='pt')\n",
    "        generated_token_ids = self.model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=40\n",
    "        )\n",
    "\n",
    "        context_with_response = [self.tokenizer.decode(sample_token_ids) for sample_token_ids in generated_token_ids]\n",
    "        return context_with_response\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=2e-5)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model = GenModel(\"ai-forever/rugpt3small_based_on_gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dm = GenDataModule(\"ai-forever/rugpt3small_based_on_gpt2\", dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fadf07f21e974f0b895ddee9a2cc3359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8010 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3ab5940a5142fab94f4996e84751da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type            | Params\n",
      "------------------------------------------\n",
      "0 | model | GPT2LMHeadModel | 125 M \n",
      "------------------------------------------\n",
      "125 M     Trainable params\n",
      "0         Non-trainable params\n",
      "125 M     Total params\n",
      "500.926   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ext-zorkina-a@ad.speechpro.com/.local/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "/home/ext-zorkina-a@ad.speechpro.com/.local/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5dac5f7b23e4e9bbda1a47401698f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=gen_model, datamodule=gen_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatGPT5():\n",
    "    \n",
    "    current = ''\n",
    "    person1 = ''\n",
    "    \n",
    "    while person1 != 'stop':\n",
    "        \n",
    "        person1 = input(\"Person 1: \")\n",
    "            \n",
    "        current += f\" <Person1> {person1}\"\n",
    "        #print(current)\n",
    "        \n",
    "        answer = gen_model.infer(current)\n",
    "        ans = answer[0][len(current):].split('<')[1].split('>')[1]\n",
    "\n",
    "        current += f\" <Person2> {ans}\"\n",
    "        \n",
    "        if person1 != 'stop': print(\"Person 2:\", ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person 1: Привет!\n",
      "Person 2:  Привет  \n",
      "Person 1: Как дела?\n",
      "Person 2:  Хорошо  \n",
      "Person 1: Чем сейчас занимаешься ?\n",
      "Person 2:  Я работаю в банке  \n",
      "Person 1: Круто! А я лабу делаю(\n",
      "Person 2:  Я тоже  \n",
      "Person 1: stop\n"
     ]
    }
   ],
   "source": [
    "chatGPT5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person 1: Какие твои любимые породы собак?\n",
      "Person 2:  Собак люблю, но не все, а только кошек  \n",
      "Person 1: stop\n"
     ]
    }
   ],
   "source": [
    "chatGPT5()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1526727,
     "sourceId": 2520208,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30616,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
